---
layout: post
title: "XSCALE: Beyond SAFe and LeSS"
date: 2014-04-21 20:46:55 +1000
author: Peter Merel
comments: true
categories: 
- eXcellent
- Scale-Symmetric
- Continuous
- Autonomous
- Lean
- Ecosystem
---

{% img /images/xscale.png %}

Reflecting our work over recent years, XSCALE is a continuously delivering,
continuously self-organizing, continuously adaptive Agile enterprise
ecosystem that turns all the knobs to ten.

<!-- more -->

**\[This post is currently in draft - don't take it too seriously yet. I
hope to finish it today but welcome feedback both from my TNG compadres and
anyone else who happens by ....\]**

## Why XSCALE?

Over the last decade there have been several efforts to provide enterprises
with a way to scale Agile. The best known are SAFe, LeSS, and the Spotify
Tribal model. Each has its strengths and weaknesses.

* [SAFe]() targets existing enterprises with a low-discipline, top-down,
  big-change-up-front, punctuated cadence model that combines Kanban,
  quarterly [release trains](), XP and Scrum. SAFe is a good starting point
  for more conservative organizations because it's designed to enable
  agility while keeping component silos intact. But this means it shys away
  from feature teams and continuous delivery, and while it targets scale it
  neglects the key enabler of scale-symmetry.

* [LeSS]()/Agile Path/Enterprise Scrum, etc., are alternatives more closely
  based on traditional Scrum. They offer high-collaboration, continuous
  cadence models that rely on [Scrum of Scrums]() to deal with integration
  and cross-cutting concerns. XP practices are optional but feature teams
  are mandatory. LeSS is big-change-up-front but Agile Path is an iterative
  alternative. All leave specific practices for product planning, test
  automation and so on for teams to determine ad hoc. 

* [The Spotify model]() dispenses with Scrum in favour of a pattern of
  [Tribes and Guilds](), strongly emphasizing bottom-up collaboration and
  team autonomy.  It gives even less prescription on team practices as it
  expects a structure of top-flight autonomous teams is capable of deciding
  for themselves how to evolve the rollout of Agile practices, but it's
  clearly committed to Continuous Delivery and DevOps with every tribe
  containing a chapter of Ops people dedicated to enabling squads to CD.
  
XSCALE naturally bears comparison to these alternatives.  Like SAFe, XSCALE
standardizes team practices using Scrum-XP. Like Agile Path, XSCALE
transforms the enterprise iteratively. Like LeSS, XSCALE refactors component
silos into feature teams. And XSCALE uses Spotify-style tribes, chapters,
guilds, CD and DevOps.

XSCALE is more than a synthesis of the best aspects of these, however. It
enables continuous adaptation using the [Seven Samurai]() patterns,
continuous product planning using Lean Startup, Lean UX and [BPP/BDD](), and
continuous enterprise self-organization using [Iroquois councils](). Its
intent is to afford enterprises absolute state of the art Agile benefits
with the lowest risk of disruption to their existing value streams.

## XSCALE Principles

XSCALE conforms with the [A:TNG values](), which form a strict superset of
those in the Agile Manifesto. XSCALE further assumes six principles that
also form a superset of those in the Manifesto.

eXcellent
: Turn all the knobs to ten.

Scale-symmetric
: Iterate distinctions to control combinations.

Continuous
: Use the smallest practical cycle time and batch size.

Autonomous
: Use consensus to make decisions and to delimit accountabilities.

Lean
: Maximize net ROI.

Ecosystem
: Continuous adaptation of the whole to its parts.

Detailed reasoning for each of these follows, and then the XSCALE practice
patterns that embody them.

### eXcellent

The word "extreme" in the original XP was controversial, and instrumental in
prompting the effort to focus the Manifesto on another word entirely.  The
Nevertheless the manifesto authors recognized its importance in a principle
that reads, "Continuous attention to technical excellence and good design
enhances agility". XSCALE calls such continuous attention "eXcellent" and
sums it up using Kent Beck's famous XP maxim:

**Turn all the knobs to ten**.

XSCALE regards the XP engineering practices, BDD, CD and Feature Teams as
the fundamentals of technical excellence. These patterns interlock to assure
technical debts are paid before they earn interest, thereby keeping the
delivery process stable, predictable and flexible. 

### Scale-symmetric

Scale is about combinations of requirements, of dependencies, of defects,
and of people. The number of combinations of a set grows very rapidly; a set
of just 10 things has over 3.6 million distinct combinations. 

Yet golfers are untroubled by vast combinations of grass blades. They make
simple distinctions to control for combined behaviours: "the green", "the
rough", and so on. Golfers never think about combinations of the individual
blades. 

Agile uses this approach when it 
* refactors code into distinct ([DRY]()) classes
* automates testing to minimize combinations of ambient defects
* combines people into distinct feature teams to limit interdependencies.  

The Spotify / Iroquois patterns also do it by factoring combinations of
conversations to small meetings with specific concerns.  The principle is:

**Iterate distinctions to control combinations**

XSCALE applies this to the challenge of determining which combinations of
business alternatives have most value. Small projects look to a good product
owner for this, but when you've got portfolios of programs of projects, it
gets hard. As agile works as a hill-climbing algorithm, continously
integrating little stories into a whole, it's actually quite happy to climb a
molehill of value when there's an Everest of it right next door.  

To control this combinatorial space XSCALE uses the Behavioral Product
Planning games, which sort breadth-first distinctions about business
alternatives into easily optimized piles. BPP iterates distinctions
breadth-first to assure consistent decisions about alternatives at all
scales. 

### Continuous

SAFe promotes Punctuated Cadence over Continuous Delivery, employing a
quarterly [release train]() integration pattern. This enables conservative
organizations to keep their component silos, but at no small price:

* Increased cost of quality due to deferring regression and acceptance
  testing to "hardening sprints".
* Wasted time in meetings to figure out how to satisfy combinatoric
  inter-team dependency cycles.
* Lost ROI from keeping finished features on ice for a quarter rather than
  releasing them as soon as they pass all tests..
* Surprises and integration overhead due to the large batch sizes involved
  in quarterly releasing.

Because it employs continuous rather than big-bang transformation, XSCALE is
able to avoid these penalties by enabling feature teams to use the GitFlow
pattern language for continuous delivery. The principal is simply:

**Always use the smallest practical cycle time and batch size**

XSCALE further applies this in its continuous product planning, continuous
stream coordination, and continuous transformation patterns.

### Autonomous

Philosophers dream of an anarchic utopia where the only law is the [Golden
Rule](). As the scale of a group increases past the [Dunbar
Number](http://en.wikipedia.org/wiki/Dunbar's_number), however, social
obligations combinatorially degrade so the [Tragedy of the Commons]() leads
to conflicts of interest that must be controlled through more restrictive
forms of society. 

Many of the benefits of Agile derive from peer collaboration and team
consensus games like planning poker and retrospectives, and it wouldn't be
reasonable to call a process Agile at any scale if it doesn't empower
consensus through games. So the XSCALE principle is:

**Use consensus to make decisions and to delimit accountabilities.**

In theory, individual accountability should be applied when the business
cost of delaying a decision is greater than the social cost of failing to
maintain consensus. In practice it's hard to figure these costs out.
Historically the happiest medium seems to have been the Iroquois
Confederacy, which used unanimous consent at sub-Dunbar scales to control a
hierarchy of peer councils. 

Where consensus protocol was violated or timing called for a rapid decision,
per-tribe "war chiefs" were made accountable. This combination of councils
and accountables proved stable at a multi-national scale over a period of
centuries. XSCALE combines it with the Spotify tribal model to scale
consensus decisions while clearly maintaining team and stream autonomy.

### Lean

Lean is often defined as "Minimizing Waste". Unfortunately that definition
admits an ambiguity. [Lean Startup](), [Lean UX]() and [LSD]() use Lean almost
as synonymous with Agile, but command and control frameworks like Lean Six
Sigma and Lean Accounting interpret Lean to mean cost reduction over ROI and
hierarchical standardization over adaptive collaboration. 

This makes the latter unsuited to our purpose in XSCALE.  To prevent confusion
XSCALE eliminates the ambiguity to define the principle simply as:

**Maximize net ROI**

We say net ROI in order to account for Cost of Delay and other factors in
projecting ROI over time. With this in mind XSCALE adapts several specific
Lean practice patterns:

* As a special case of Breadth-first Roadmapping, Lean Startup's [business
  model canvas]() to pivot and refactor the enterprise's value streams
* Per stream [Value Stream Maps]() converted to a [Lean Kanban]() and
  [cumulative flow diagrams]() to represent the relationship between stream
  funding, stream return, and the stream roadmap
* [Product Teams]() working cross-functionally per Lean UX to coordinate
  [set-based-design]() with lo-fi prototyping, BDD and Feature roadmaps
* [Lean Transformation Canvas]() as a roadmap for the [Seven Samurai]().

These Lean practices all work to maximise net ROI. XSCALE interlocks them
using scale-symmetric roadmapping to render a stream funding cycle without
resorting to project budgets and baselines yet remaining continuously
responsive to metrics and learnings for the teams in the stream and for the
market for the stream's output.

### Ecosystem

We have become used to combining the noun ecosystem with the adjective
fragile. This is an artefact of the [anthropocene era]() where biological
ecosystems are undergoing catastrophic change. 

The prime characteristic of an ecosystem, however, is not fragility, but
agility - that it embraces cycles of change to maintain stable behaviours
over time.  A living ecosystem differs from a zoo in that it has evolved to
continuously adapt to cycles of change in the behaviour of its constituent
organisms.  

The biological principles are sex and death.  Sex continously generating
experimental variations on behaviour, and death removing variations that
don't efficiently adapt to the whole. In XSCALE we can think of Lean
pivoting and set-based design serving the function of sex, and Agile
refactoring serving that of death, but the principle of the ecosystem
remains the same:

**Continuous adaptation of the whole to its parts**

This isn't just about products and their features, but the structure and
practices of teams in streams and streams in the enterprise. The ecosystem
principle turns the Taylorist conceit of all-wise managers and serf-like
workers on its head, leveraging the Agile function of management as
[servant-leaders]() to autonomous teams of peer workers.

In order to pivot and refactor the enterprise as a whole, XSCALE relies on a
hierarchy of Iroquois councils: 

* chapters as groupings of people with common capabilities across squads 
* stream councils composed of chapter representatives
* an enterprise council composed of stream council representatives. 

At each level there are specific accountabilities defined by the teams.
Each squad in a stream has distinct roles for agile coach and product owner.
Each stream has a lead product owner and a lead coach. And the enterprise
has its executive officers. 

The accountabilities of these roles are defined by treaty in their
respective councils. The accountability of the enterprise as a whole, and
each of its streams, and each of their chapters is dynamically defined by a
treaty in story-normal form. This story is expanded using the
**Breadth-First Roadmap** method described below.

## XSCALE Practice Patterns

XSCALE is "opinionated" in the same sense as [Ruby on Rails]().  This means
you'll want to follow its practices very closely to begin with - because this
is how it "turns all the knobs to ten".  

Because XSCALE isn't a big-change-up-front framework, as it grows and you gain
experience the various councils will collaboratively vary its practices to
adapt them to the whole. Nevertheless, the following provides a well proven
starting point.

### Enterprise Practices

XSCALE adopts the [Beyond Budgeting]() premise that each value stream must
either earn its keep or convince other, self-funded streams that it is worth
their investing some part of their revenue to fund it. This is not to
disempower executives, but to assure that the entire enterprise pivots
collaboratively to improve ROI.

Therefore, while we describe these patterns as "Enterprise Practices", this
doesn't mean they're only performed in the stratosphere.  The same patterns
are employed by squads, streams, and the enterprise council to optimize their
courses of action, and reconcile them with available funding. As a pattern
language based on and generating BDD we also refer to them collectively as
Behavioral Product Planning or "BPP".

#### Feature Points, Story Points and Normalized Story Points

In BPP we change the unit of estimation from story points to feature points.
Where story points represent only the relative effort required to deliver a
story, feature points estimate increments of funding necesssary to deploy a
whole feature. Because the number of story points that will fit into a
funding increment depends on team velocity at the time of delivery, there's
no linear mapping between feature points and story points, and no need to
attempt to normalize story points across teams.

Instead the Backlog Bingo practice gives feature points an empirical basis in
relation to previously delivered features. XSCALE uses these feature points
both in establishing a reasonable level of funding per business objective,
and as a direct input to the "RoI+CoD" prioritization method.  Where it is
necessary to represent both feature points and story points on a stream flow
diagram, we simply monetize story points using the formula:

Monetized Story Points = Story Points / Feature Velocity

Where Feature Velocity is the squad's weekly throughput in story points per
feature point. If, for example, a squad costs its stream 10 feature points
per week, and delivers 25 story points in that week, its velocity is 2.5
SP/FP. This is functionally equivalent to the traditional Agile measure of
project velocity, but because it's normalized to feature points it becomes
trivial to do the arithmetic projecting the various velocities of multiple
squads in a stream.

#### Breadth-First Roadmap

{% img /images/lean-startup.png %}

Breadth-First Roadmap (BFR) is a generalization of the Lean Startup [Business
Model Canvas]() composed of simple, commonplace Agile practices - story normal
form, INVEST properties and categories of BDD acceptance criteria. Its
function is to concrete shared understanding of a group's delivery targets or
courses of action, and assure complete analysis of same to a limited depth.

XSCALE applies BFR at an enterprise level to determine what value streams are
required to realize a business model. At a stream level we use it to determine
the features of products and services required to achieve the stream's
business objectives. And delivery squads can also use BFR to determine the
stories required to deliver a feature.

Therefore every BFR can be regarded as an expansion of a single, larger
**scoping story**.  It's important to begin by describing this story in
[story-normal form]() in order to scope roadmapping conversations to a single
shared intent.

{% img /images/roadmap0.png %}

* At every level, BFR takes the form of a matrix of objectives and themes
  where a theme defines a category of acceptance criteria for a cross-cutting
  technical, business or user experience concern and the objectives combine to
  satisfy the scoping story respecting these themes.
* Each objective expands to a set of sub-features in story-normal form.  These
  features are checked to assure their INVEST compliance. Here the S in INVEST
  is generalized to mean "scale similar" rather than just "small".
* The intersection of a feature and a theme is simply a checkbox; each box can
  only contain a blank or a checkmark. A checkmark means there are acceptance
  criteria for this feature in this theme and a blank means there aren't.

{% img /images/roadmap1.png %}

* Each feature is evaluated against all themes. 
* As each feature is evaluated, also consider whether there are acceptance
  criteria in a theme that isn't yet part of the roadmap. If so, add a column
  for that theme and re-evaluate all the features to determine whether they
  also have some acceptance criteria in it.
* It's fine to modify or refactor features as you go so long as all the
  roadmap's boxes are consistently updated.

{% img /images/roadmap2.png %}

* Evaluate each theme to determine whether it is sufficiently covered by
  features to achieve the scoping story.
* If not, the roadmap should be extended with extra features to assure the
  theme is sufficiently covered, with these features subsequently evaluated in
  all themes.
* If it appears that all features have the same pattern of checkboxes for two
  themes, consider whether those two may be refactored into one.

{% img /images/roadmap3.png %}

* If a theme has checkboxes for all or almost all features, break out further
  features to encapsulate shared technical infrastructure to economically
  support the commonalities. We call these **technical features**.
* If a theme has no checkboxes ticked, it may simply be deleted. If it has
  only a very small number ticked, it may be better to convert the sparse
  theme into a feature.
* In general this  process continues until the team agrees that the roadmap is
  complete or there is no more time available.

To use BFR properly it's important to keep "breadth-first" in mind. The
roadmapping process may become long and onerous if features and themes are too
numerous or detailed for the scale of the roadmap. Each feature will be
expanded into a further roadmap at the next level down until they're small
enough to constitute delivery stories. So it's counterproductive to
over-specify them.

#### Backlog Bingo

The original XP Planning Game, now known as "Planning Poker", is a proven way
for delivery teams to collaborate on estimating the relative effort required
to collaboratively deliver a set of stories. XSCALE generalizes Planning Poker
to make a method of determining the funding required to deliver a set of
products and services. 

Backlog Bingo is very easy to play:

* Write [Fibonacci numbers]() from 1 to 89 on cards and lay them out in a row
  across a large table. There's nothing magical about Fibonacci numbers - we
  use them because they consistently lead people to think in terms of
  trade-offs - is feature A really as big as feature B + feature C, and so on.

* Select three previously delivered and deployed features with well documented
  costs, one small, one medium and one large. Call these **probes**. Describe
  each probe in story-normal form commensurable with the roadmap features you
  want to estimate.

* Figure out a funding increment that constitutes the greatest common divisor
  of the probes' respective costs and call this a feature point. Place the
  three probes under the Fibonacci numbers that match their respective
  magnitudes in feature points. 

* Pick a feature from your roadmap. Compare it with the probes, starting with
  the middle one, to evaluate its relative size in Fibonacci multiples of
  feature points.

* As you add features, sort them into the appropriate Fibonacci column.
  Continue to compare features this way until there are none left to compare.
  If the estimators cannot agree on the Fibonacci number for a feature,
  split it into pieces they can estimate separately.

Bingo can also be used without a dollar basis to estimate relative business
value. You simply pick a different set of 3 probes - one for an existing
deployed feature that the PO says has low business value, and then one
that's crticially important to business function, and then one roughly in
between. Place them at 3, 13 and 55, respectively, and the rest of the Bingo
game runs as above.

#### Royal Cod Prioritization

RoI+CoD (which we affectionately call "Royal Cod") is a simple consensus game
to prioritise the BFR. It is both easier and more accurate than the SAFe
"Weighted Shortest Job First" (WSJF) equivalent for reasons described below.

RoI+CoD uses two Bingo sessions to assign values to the BFR features in terms
of:

* effort in feature points
* relative business value

Technical team members - developers, architects, designers and testers - play
the first bingo game with Product Owner and stakeholders in the room to
answer questions and also to question any estimate they feel is too large or
too small. 

The second bingo game reverses the roles. Now it's business stakeholders,
SMEs and the PO who work together to estimate business value while technical
team members answer questions. 

Only technical team members are qualified to make effort estimates, and only
business team members to make business value estimates. Once each feature
obtains both estimates, RoI+CoD prioritisation involves three steps:

* Divide the business value number, which represents expected return, by
  effort, which represents the required investment to obtain the return.
  This yields relative return on investment - RoI.
* List features vertically in order of decreasing RoI. Let the Product Owner
  increase the priority of any business feature if they feel has a Cost of
  Delay (CoD) that warrants this.
* Once the PO is content with the prioritisation of business features, let
  technical team members increase the priority of any technical feature they
  feel has a CoD that warrants this. 
  
In order to minimize the overall cost of maintenance, a technical feature
should have a priority no more than one rank higher than the highest prioity
feature that depends upon it.

Once the CoD adjustments have been made, record the relative priorities of
the features to prepare them for Roadmap Refactoring, which will determine
how to best fit them given funding constraints and MVP per business objective. 

#### Royal Cod vs WSJF

Why not WSJF? WSJF is defined in SAFe by the formula (Business/User Value +
Criticality + Risk-Reduction-or-Opportunity-Enablement) / Duration. Since
there's no clear distinction between business value, risk reduction and
opportunity enablement, nor between criticality and Cost of Delay, WSJF
simplifies to (Business Value / Duration) + (Criticality / Duration).

There are several problems with this:
0. It doesn't makes sense to divide criticality by duration. Work doesn't
   become less critical just because it takes longer. This trade-off must be
   made intelligently, not numerically.
-  Without clear relative distinctions, which aren't provided by SAFe there's
   no way to assure that variables are independent. This distorts relative
   Business Value in an unpredictable way.
-  By factoring CoD variables and giving them equal weighting WSJF actively
   prevents trade-off conversations that would reconcile differing
   assumptions about the features.
-  WSJF provides no opportunity to account for how combinations of features
   render the individual feature more or less valuable. This is a moving
   target that requires explicit conversation.
-  WSJF doesn't account for technical CoD.  Some features may have high CoD
   because of architectural concerns or business uncertainty. WSJF just
   leaves that out.

All of these problems are eliminated by BPP. Once you've factored out ROI, it
becomes easy for team members to determine the remaining CoD.  And rather
than adding in CoD as if it were linear, which it's not, it's easy for team
members to adjust an ROI prioritization by discrete CoD. BPP also accounts
for technical CoD of technical features. The result is quick, easy and
completely unambiguous.

#### BPP Uncertainty

Uncertainty can lead technical team members to refuse to estimate a feature.
In this case they must clearly describe the ambiguities or inconsistencies
they would need resolved by the Product Owner in order to produce an
estimate. If the product owner can't resolve the entire problem, and part of
the feature is estimable but another part is not:

* the feature is split into two, 
* the estimable part is estimated
* a new technical feature is created to represent the work of resolving the
  uncertainty via [spikes]() or a [set-based design]() process.
* estimating the inestimable feature is deferred until the technical feature
  it depends upon is completed.

If a large number of features are inestimable it's usually best to defer this
bingo session until the team has had time to work with architects and
designers to nail dependencies down a bit better, or analysts have sufficient
time to resolve unsolved business questions.

#### Roadmap Refactoring

Roadmap Refactoring (RR) is a consensus game that leverages BPP to enable
product owners to make rational trade-offs between different feature-sets. It
can be used to quickly assemble a release plan to hit a particular date, if
need be, or to determine an ordering of feaure sets to maximize
product-market fit within the funding profile of a continuous delivery
stream.

Like the other XSCALE enterprise practices, RR is a quick consensus game with
very straightforward rules:

0. Using the BPP prioritization, lay out all available features in columns
   grouped by business objective.
0. Pick the first column. Pick the feature at the top of the column. Let the
   PO as advised by their product team determine whether the objective can be
   met without including that feature. 
0. Continue feature by feature until the PO sees one that, while still
   valuable, could be left out without preventing satisfaction of the column
   objective.
0. All of the features above that one constitute the minimum viable
   featureset for that objective. Call them "bronze". 
0. Continue to pick features in that column now asking the PO whether the
   feature has a concrete quantified business value, or just seems "nice to
   have". Call the former "silver" and the latter "gold".
0. Total how many feature points are in each of the bronze, silver and gold
   levels for that column.
0. Do this for all columns.
0. If fitting to a continuous delivery funding model, POs simply prioritize
   the bronze, silver and gold tranches of features across all columns.  Pick
   the most important one, then the next most important one, and so on.  Use
   the feature points to project release dates for marketing and other
   business development purposes.
0. If you're only playing to create a release plan for a particular
   date/budget, determine how many feature points correspond to that release.
   Now let the PO determine which combination of bronze/silver/gold levels
   will maximize deployed value for that release.
0. Record all of these decisions as an easy  starting point for the next RR
   session.

Roadmap Refactoring is played whenever new features are added to the stream
backlog or whenever the PO calls for it. Because it's such a quick game it's
also possible to play in a "what-if" mode to evaluate alternative product
plans to evaluate possible responses to changes in market conditions.

### Stream Practices

#### Stream Structure

By a Stream we mean a Spotify-structured tribe that self-organizes around
standardized Delivery and Adaptation Kanbans and an [Iroquois Council]() made
up of rotating Chapter representatives, We call this a stream rather than a
tribe to emphasize the responsibility and instrumentation of the tribe as
a Lean value stream.

Because the [Spotify
model](http://blog.kevingoldsmith.com/2014/03/14/thoughts-on-emulating-spotifys-matrix-organization-in-other-companies/)
supports a
[semi-lattice](http://www.bp.ntu.edu.tw/wp-content/uploads/2011/12/06-Alexander-A-city-is-not-a-tree.pdf)
rather than hierarchic enterprise structure, it is more natural, more
flexible and more responsive to change than traditional corporate structures.
As Chris Alexander says, "As the relationships between functions change, so
the systems which need to overlap in order to receive these relationships
must also change". 

This is clearly reflected in the Spotify experience where
"We can spin up a new squad to take advantage of an opportunity or handle an
issue without worry about changing reporting structures. If a squad completes
its goals and has no reason to exist anymore, we can dissolve it without
punishing a manager".

XSCALE augments the Spotify Model with a consensus decision-making pattern
derived from the historical Iroquois Confederacy. The use of this pattern to
focus and coordinate decision-making in squads, streams and the enterprise as
as whole is described in the **Continuous Adaptation** section below.

#### Stream Flow Diagram

{% img images/stream-cf.png %}

Every Stream is intended to generate a return. If the Stream is purely
internal then its return may simply be defined as equal to its funding. An
external facing Stream generally begins with an investment of funds by the
enterprise intended to kickstart sufficient revenue that it is more than
self-funding.

XSCALE represents the return and the funding for a Stream in terms of Feature
Points on a cumulative flow diagram. Because this diagram takes a specific
form in XSCALE we call it a "Stream Flow Diagram". Note that where we
refer to story points here we actually mean Monetized Story Points derived
from the formula given in the Feature Points section above. The layers of the
Stream Flow diagram represent, from bottom to top:

* deployed features
* integrated but undeployed stories 
* implemented but unintegrated stories
* estimated but unimplemented stories
* features with stories covered by BDD scenarios
* BPP best market fit of features to funding 
* squad/stream funding limit over time
* stream revenue over time

Stream Flow can represent all of these flows on one consistent diagram per
squad. Because of normalization to feature points these are trivially rolled
up per stream, and then to the enterprise as a whole. This is extremely
enlightening because it is directly amenable to traditional Lean analysis of
cycle time, latency, WIP, etc. This provides unambiguous and immediately
actionable identification of wastes, bottlenecks, irregularities and
opportunities, as well as their relative magnitudes. 

### Team Practices

#### DevOps + CD + GitFlow

* Iterations are 1 week long. Features (defined as groups of stories that when
  deployed together will delivery some concrete business value) are assigned
  one per delivery squad. Delivery is automated and features are delivered
  asynchronously by squads as they're completed.

* Per the Spotify model, each squad has all the skills and capabilities it
  needs to delivery a feature. Per DevOps, Ops forms a chapter that does not
  gate deployment, but provides delivery squads with automated deployment
  tools and channels that enable them to test and integrate stories and deploy
  features independently.

* Ops maintains virtualization via Mock Objects, Data Fixtures, BDD step
  implementations and [Service Virtualization Tools]() to assure that tests
  cannot interfere with one another and that the behaviour of virtual and
  production-like SIT environments is equivalent under test.

#### Lean UX + BDD + XP

* Streams use the Lean UX [Product Team]() pattern where designers, analysts,
  SMEs, architects and product owners work together to break features down
  into stories to supply a set of delivery squads. To comform with the Spotify
  structure the Product Team takes the form of a chapter. Whenever the Product
  chapter is not meeting its members spend time collaborating with the
  delivery squads.

* Stories are produced in [Gherkin]() format factored to maintain [INVEST]()
  properties. Squads get together with the Product Team every Wednesday
  afternoon to estimate its latest batch of stories.
  
* A story with INVEST defects is returned without an estiamte to the Product
  Team for clarification. Otherwise the throughput of the Product Team is
  graphed on the [Stream CF diagram]() in terms of new estimated story points
  per week.

* Squads hold reviews and retrospectives every Friday and task breakout
  sessions every Monday. Their CF diagrams roll up together to inform the
  Stream CF diagram's metrics for implemented stories, integrated stories,
  and deployed features.

### Enterprise Practices

As per the [Seven Samurai]() pattern language, XSCALE starts by constructing
a "Minimum Viable Agile Capability" - a "spike" squad within a single stream
that forms a model for all those to come.  The spike squad prototypes and
proves its tools, relationships and processes integrate as and efficient end
to end SDLC by delivering a stream of small concrete features with real
business value.

This is the familiar Agile [steel thread]() pattern applied to organizing an
Agile capability. To avoid pain at scale, Before iterating the growth of
further squads all the technical and organizational fundamentals must be
reliably integrated.

Technically, assembling this enterprise steel thread is the direct
responsibility of the spike squad. To continuously integrate this squad with
the pre-existing organization, [Seven Samurai]() assembles a Stream Council
from the lead doers - not deciders - from each of the organization's
pre-existing component silos.  As delivery squads multiply, these leads 
also function as chapter representatives on the Stream Council.

Meanwhile progressive senior managers form the initial Enterprise Council
with support from coaches again per the Samurai patterns. As XSCALE is
adopted by more streams, their managers will take part in their respective
councils and thereby become stream reps on the Enterprise Council. This
assures smooth, consistent, iterative rollout of XSCALE across the whole
organization.

#### Chapter, Squad, Guild and Council Meeting Schedule

As XSCALE rolls out it becomes advantageous to synchronize council meetings
so that they don't cause calendar-stress. XSCALE leverages the weekly cycle
to achieve this:

* All of a stream's chapters meet simultaneously every Friday lunch so that
  squad activities aren't interrupted. Chapters may also meet at other
  times coordinating via their Stream Council.

* At the Friday lunch meeting a Chapter selects its representatives for the
  Stream Council, which is conducted immediately afterward while squads are
  conducting their weekly reviews. To avoid waste, time and location for
  reviews, retros and council meetings should be pre-determined and
  synchronized.

* Squad retrospectives are held immediately following the Stream Council
  meeting so that any treaties proposed by Council can be immediately and
  unanimously ratified. If ratification of a treaty is not achieved, a further
  Council meeting may be held immediately after the squad retros to sort the
  matter out. If polarization occurs here then the Stream Lead may force
  temporary (1 week) adoption of a treaty while offline discussions resolve
  it at chapter level.

* Guild meetings are held asynchronously on a frequency determined by their
  respective Stream Councils.

* Enterprise Council meetings are held on a frequency determined by the
  Enterprise Council, and asynchronously whenever a Stream Council calls for
  one.

#### Chapter and Council Roadmaps

As explained in the Ecosystem section above, Streams and Squads have their
specific purposes distinguished by treaties in story-normal form.  Councils
and Chapters adapt and expand the respective treaties by means of
Breadth-First Roadmaps that detail how they will organize themselves to
satisfy the terms of the treaty. Then the BPP patterns are applied to
estimate and prioritize these roadmaps using themes drawn from the Seven 
Samurai patterns to reflect the respective accountabilities and
responsibilities at each level:

* Chapters are accountable for Adoption and Acceleration, responsible for
  Awareness and Architecture.
* Stream Councils are accountable for Awareness and Architecture,
  responsible for Assessment and Analysis,
* The Enterprise Council is Accountable for Assessment and Analysis,
  responsible for Alignment and Appropriation

Each council uses a kanban to track the progress of features drawn the
backlog resulting from applying BPP to its roadmap with cumulative flow
diagrams used to represent progress of the transformation over time.

#### Stream Funding cycle

\[text almost done ...\]
